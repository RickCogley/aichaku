# Iteration Plan: Learning Through Usage

## Status: ACTIVE - PLANNING MODE
## Date: 2025-07-06

## Core Principle
"We need to actually use it to see how it works, then iterate" - This is our guiding approach.

## Phase 1: MVP (This Release - v0.3.0)

### What We'll Build
- Basic adaptive behavior (all methodologies installed)
- Simple vocabulary mappings
- Initial blending instructions
- User customization structure

### What We'll Learn
- Does the AI actually pick up on methodology cues?
- Which methodologies blend naturally?
- What vocabulary causes confusion?
- How do users want to customize?

### Success Criteria
- Installation works smoothly
- AI responds to basic methodology terms
- Users can add customizations
- No major confusion

## Phase 2: First Iteration (v0.3.x)

### Based on Usage, We Might Add:
- Refined vocabulary mappings
- Better blending examples
- Common customization templates
- Debug mode to see why AI chose certain methods

### Questions to Answer:
- Do users actually blend methodologies?
- Which combinations are most common?
- What terminology trips up the AI?
- Do organizations ask for strict mode?

## Phase 3: Maturity (v0.4.0)

### Potential Features (Based on Feedback):
- Methodology lock configuration
- Organization templates
- Success pattern library
- Integration with CI/CD for docs

### Only If Users Request:
- Strict mode enforcement
- Compliance reports
- Methodology metrics
- Team dashboards

## Testing Approach

### 1. Dogfooding
- Use Aichaku to manage Aichaku development
- Document what works/doesn't
- Refine based on experience

### 2. Beta Users
- Find 5-10 teams willing to try it
- Different industries/sizes
- Weekly feedback sessions
- Real project usage

### 3. Feedback Loops
- GitHub discussions for ideas
- Issue tracking for problems
- Usage analytics (with consent)
- Community contributions

## Key Metrics

### Quantitative
- Installation success rate
- Methodology blending frequency
- Customization file creation
- Upgrade success rate

### Qualitative
- "This feels natural" vs "This is confusing"
- "It helped me" vs "It got in the way"
- "I'd recommend it" vs "It needs work"

## Anti-Patterns to Avoid

1. **Feature Creep**: Adding features before validating need
2. **Over-Engineering**: Complex solutions to simple problems
3. **Methodology Purism**: Forcing "correct" usage
4. **Analysis Paralysis**: Endless planning without shipping

## Commitment to Simplicity

Even as we iterate:
- Keep the core simple
- Add only validated features
- Remove what doesn't work
- Stay true to adaptive vision

## The Build-Measure-Learn Cycle

### Build (v0.3.0)
- Simple adaptive system
- Basic blending
- User customization

### Measure
- How do people actually use it?
- What problems do they hit?
- What delights them?

### Learn
- Which assumptions were wrong?
- What patterns emerge?
- What's the next most valuable feature?

## Remember

As you noted: Some things need to be "set in stone" (like final deliverables), while execution can be flexible. Aichaku should enhance this natural balance, not fight it.

The goal isn't to create the perfect methodology tool - it's to reduce friction in AI-assisted project management.